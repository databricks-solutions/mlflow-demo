{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Review: Expert Feedback for GenAI Quality\n",
    "\n",
    "App developers are most often not domain experts in the business use case, and therefore, need help from domain experts to understand what is a low vs high quality response. MLflow's labeling capabilities enable domain experts to systematically review and label GenAI application traces with ground truth, providing invaluable insights to tune your automated quality metrics and understand how your application should respond.\n",
    "\n",
    "Key benefits:\n",
    "\n",
    "- **Expert validation** - Domain experts can review traces and provide structured feedback on quality dimensions\n",
    "- **Systematic labeling** - Create consistent labeling schemas that capture business-critical quality aspects\n",
    "- **Quality improvement loop** - Convert expert feedback into training data for LLM judges and evaluation benchmarks\n",
    "\n",
    "MLflow's Review App provides a pre-built UI, designed for business users, that anyone in your company can use, even if they don't have access to your Databricks workspace.\n",
    "\n",
    "![human-feedback-overview](https://i.imgur.com/7LNlgDP.gif)\n",
    "\n",
    "This notebook demonstrates how to collect expert feedback through MLflow's labeling capabilities. You'll learn to create labeling sessions, add traces for review, and access the Review App for systematic quality improvement through human-in-the-loop evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages (only required if running in a Databricks Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eric.peter/Github/mlflow_genai_email_demo/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dbutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall -U -r ../../requirements.txt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdbutils\u001b[49m.library.restartPython()\n",
      "\u001b[31mNameError\u001b[39m: name 'dbutils' is not defined"
     ]
    }
   ],
   "source": [
    "%pip install -U -r ../../requirements.txt\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Load environment variables and verify MLflow configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T14:22:20.753597Z",
     "iopub.status.busy": "2025-07-29T14:22:20.753408Z",
     "iopub.status.idle": "2025-07-29T14:22:20.766874Z",
     "shell.execute_reply": "2025-07-29T14:22:20.766574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Local IDE\n",
      "=== Environment Setup ===\n",
      "DATABRICKS_HOST: https://db-ml-models-prod-us-west.cloud.databricks.com\n",
      "MLFLOW_EXPERIMENT_ID: 1203903883862022\n",
      "LLM_MODEL: databricks-claude-3-7-sonnet\n",
      "UC_CATALOG: ep\n",
      "UC_SCHEMA: notes_test2\n",
      "‚úÖ Environment variables loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "from mlflow_demo.utils import *\n",
    "\n",
    "if mlflow.utils.databricks_utils.is_in_databricks_notebook():\n",
    "  print(\"Running in Databricks Notebook\")\n",
    "  setup_databricks_notebook_env()\n",
    "else:\n",
    "  print(\"Running in Local IDE\")\n",
    "  setup_local_ide_env()\n",
    "\n",
    "# Verify key variables are loaded\n",
    "print('=== Environment Setup ===')\n",
    "print(f'DATABRICKS_HOST: {os.getenv(\"DATABRICKS_HOST\")}')\n",
    "print(f'MLFLOW_EXPERIMENT_ID: {os.getenv(\"MLFLOW_EXPERIMENT_ID\")}')\n",
    "print(f'LLM_MODEL: {os.getenv(\"LLM_MODEL\")}')\n",
    "print(f'UC_CATALOG: {os.getenv(\"UC_CATALOG\")}')\n",
    "print(f'UC_SCHEMA: {os.getenv(\"UC_SCHEMA\")}')\n",
    "print('‚úÖ Environment variables loaded successfully!')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T14:22:20.791260Z",
     "iopub.status.busy": "2025-07-29T14:22:20.791138Z",
     "iopub.status.idle": "2025-07-29T14:22:23.314223Z",
     "shell.execute_reply": "2025-07-29T14:22:23.313386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get helper functions for showing links to generated traces\n",
    "from mlflow_demo.utils import generate_labeling_schema_link,generate_labeling_session_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è Step 1: Create Labeling Schemas\n",
    "\n",
    "Define structured feedback schemas that capture the quality dimensions important to your business. These schemas guide reviewers to provide consistent, actionable feedback that can be used to improve automated quality assessment.\n",
    "\n",
    "**Schema Design Best Practices**\n",
    "\n",
    "- **Simple Yes/No questions** are easier for reviewers and provide clear signals\n",
    "- **Detailed instructions** help ensure consistent labeling across reviewers\n",
    "- **Enable comments** to capture qualitative insights beyond the binary rating\n",
    "- **Focus on business-critical dimensions** rather than generic quality aspects\n",
    "\n",
    "**üìö Documentation**\n",
    "\n",
    "- [**Expert Feedback**](https://docs.databricks.com/aws/en/mlflow3/genai/human-feedback/expert-feedback/label-existing-traces)\n",
    "- [**Labeling Schemas**](https://docs.databricks.com/aws/en/mlflow3/genai/human-feedback/concepts/labeling-schemas)\n",
    "\n",
    "**‚ñ∂Ô∏è Run the next cell to create email quality assessment schemas!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T14:22:37.708780Z",
     "iopub.status.busy": "2025-07-29T14:22:37.707308Z",
     "iopub.status.idle": "2025-07-29T14:22:41.448668Z",
     "shell.execute_reply": "2025-07-29T14:22:41.448099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Creating labeling schemas for email quality assessment...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Label schema with name 'accuracy' already exists and will be overwritten. This impacts any labeling sessions using this schema.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created schema: **accuracy**\n",
      "   üìù Title: Are all facts accurate?\n",
      "   üí° Type: feedback\n",
      "   üìã Instructions: Check that all information comes from customer data with no fabrication or error...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Label schema with name 'personalized' already exists and will be overwritten. This impacts any labeling sessions using this schema.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created schema: **personalized**\n",
      "   üìù Title: Is this email personalized?\n",
      "   üí° Type: feedback\n",
      "   üìã Instructions: Evaluate if the email is tailored to this customer's specific situation and cann...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Label schema with name 'relevance' already exists and will be overwritten. This impacts any labeling sessions using this schema.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created schema: **relevance**\n",
      "   üìù Title: Is the email relevant to this customer?\n",
      "   üí° Type: feedback\n",
      "   üìã Instructions: Check if urgent issues are prioritized first and content follows proper importan...\n",
      "\n",
      "üîó View labeling schemas in MLflow UI:\n",
      "   üè∑Ô∏è Label Schemas: https://db-ml-models-prod-us-west.cloud.databricks.com/ml/experiments/1203903883862022/label-schemas\n"
     ]
    }
   ],
   "source": [
    "from mlflow.genai import label_schemas\n",
    "\n",
    "# Create comprehensive labeling schemas for email quality assessment\n",
    "# Note that we intentionally use the same names as our scorers - this allows us to see the LLM scores alongside human labels in the UI.\n",
    "schema_configs = {\n",
    "  'accuracy': {\n",
    "    'title': 'Are all facts accurate?',\n",
    "    'instruction': 'Check that all information comes from customer data with no fabrication or errors.',\n",
    "    'type': 'feedback',  # Subjective assessment\n",
    "  },\n",
    "  'personalized': {\n",
    "    'title': 'Is this email personalized?',\n",
    "    'instruction': \"Evaluate if the email is tailored to this customer's specific situation and cannot be reused for others.\",\n",
    "    'type': 'feedback',\n",
    "  },\n",
    "  'relevance': {\n",
    "    'title': 'Is the email relevant to this customer?',\n",
    "    'instruction': 'Check if urgent issues are prioritized first and content follows proper importance order.',\n",
    "    'type': 'feedback',\n",
    "  },\n",
    "}\n",
    "\n",
    "print('üìã Creating labeling schemas for email quality assessment...\\n')\n",
    "\n",
    "# Create label schemas using MLflow's label_schemas API\n",
    "created_schemas = {}\n",
    "for schema_name, config in schema_configs.items():\n",
    "  # Create schema with proper configuration following documentation patterns\n",
    "  schema = label_schemas.create_label_schema(\n",
    "    name=schema_name,\n",
    "    type=config['type'],\n",
    "    title=config['title'],\n",
    "    input=label_schemas.InputCategorical(options=['yes', 'no']),  # Simple binary choice\n",
    "    instruction=config['instruction'],\n",
    "    enable_comment=True,  # Enable comments\n",
    "    overwrite=True,  # Allow updating this schema if it exists\n",
    "  )\n",
    "  created_schemas[schema_name] = schema\n",
    "  print(f'‚úÖ Created schema: **{schema_name}**')\n",
    "  print(f'   üìù Title: {config[\"title\"]}')\n",
    "  print(f'   üí° Type: {config[\"type\"]}')\n",
    "  print(f'   üìã Instructions: {config[\"instruction\"][:80]}...')\n",
    "  print()\n",
    "\n",
    "generate_labeling_schema_link();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Step 2: Create Labeling Session\n",
    "\n",
    "Create a labeling session that combines the schemas. A Labeling Session is a special type of MLflow Run organizes a set of traces for review by specific experts using selected labeling schemas. It acts as a queue for the review process.\n",
    "\n",
    "**üìö Documentation**\n",
    "\n",
    "- [**Expert Feedback**](https://docs.databricks.com/aws/en/mlflow3/genai/human-feedback/expert-feedback/label-existing-traces)\n",
    "- [**Labeling Sessions**](https://docs.databricks.com/aws/en/mlflow3/genai/human-feedback/concepts/labeling-sessions)\n",
    "\n",
    "**‚ñ∂Ô∏è Run the next cell to create a session**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T14:22:41.450518Z",
     "iopub.status.busy": "2025-07-29T14:22:41.450362Z",
     "iopub.status.idle": "2025-07-29T14:22:42.310924Z",
     "shell.execute_reply": "2025-07-29T14:22:42.309923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Creating labeling session...\n",
      "\n",
      "‚úÖ Created labeling session: Email quality review\n",
      "üîó View labeling sessions in MLflow UI:\n",
      "   üè∑Ô∏è Labeling Session: https://db-ml-models-prod-us-west.cloud.databricks.com/ml/experiments/1203903883862022/labeling-sessions?selectedLabelingSessionId=0ab987d3-42b7-4d45-9a93-c301d4e7b3e6\n"
     ]
    }
   ],
   "source": [
    "# Create labeling session following MLflow documentation patterns\n",
    "import mlflow\n",
    "\n",
    "print('üìù Creating labeling session...\\n')\n",
    "\n",
    "# Create session with timestamp to ensure uniqueness (following docs pattern)\n",
    "session_name = f'Email quality review'\n",
    "\n",
    "# Create labeling session with proper configuration\n",
    "labeling_session = mlflow.genai.create_labeling_session(\n",
    "  name=session_name,\n",
    "  assigned_users=[],  # Users can be assigned later via the MLflow UI\n",
    "  label_schemas=['accuracy', 'personalized', 'relevance'],  # Use the schemas created above\n",
    ")\n",
    "\n",
    "print(f'‚úÖ Created labeling session: {session_name}')\n",
    "generate_labeling_session_link(labeling_session.labeling_session_id);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Step 3: Add Traces to Labeling Session\n",
    "\n",
    "Now we'll add traces to our labeling session so domain experts can review them. This step demonstrates how to programmatically add specific traces that need expert feedback.\n",
    "\n",
    "### **IMPORTANT**: In this notebook, we show you how to view this data using the MLflow SDKs. You can also perform these same steps using the MLflow Experiment UI.\n",
    "\n",
    "![add](https://i.imgur.com/mOrdoF5.gif)\n",
    "\n",
    "**üìö Documentation**\n",
    "\n",
    "- [**Add Traces to Labeling Session**](https://docs.databricks.com/aws/en/mlflow3/genai/human-feedback/expert-feedback/label-existing-traces#step-4-generate-traces-and-add-to-the-labeling-session)\n",
    "\n",
    "**‚ñ∂Ô∏è Run the next cell to add traces to the labeling session!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T14:22:42.315345Z",
     "iopub.status.busy": "2025-07-29T14:22:42.314941Z",
     "iopub.status.idle": "2025-07-29T14:22:43.591691Z",
     "shell.execute_reply": "2025-07-29T14:22:43.590159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for production traces to add...\n",
      "‚úÖ Added 5 traces to labeling session: Email quality review\n",
      "üîó View labeling sessions in MLflow UI:\n",
      "   üè∑Ô∏è Labeling Session: https://db-ml-models-prod-us-west.cloud.databricks.com/ml/experiments/1203903883862022/labeling-sessions?selectedLabelingSessionId=0ab987d3-42b7-4d45-9a93-c301d4e7b3e6\n"
     ]
    }
   ],
   "source": [
    "print('üîç Searching for production traces to add...')\n",
    "# Get 5 traces from  from the current experiment\n",
    "# The tag is used to identify the traces that the demo initially loaded - think of this as your production set of traces from real users.\n",
    "traces = mlflow.search_traces(max_results=5, filter_string='tags.sample_data = \"yes\"')\n",
    "\n",
    "labeling_session.add_traces(traces)\n",
    "\n",
    "print(f'‚úÖ Added {len(traces)} traces to labeling session: {session_name}')\n",
    "\n",
    "generate_labeling_session_link(labeling_session.labeling_session_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è Step 4: Share the Review App with your domain experts and label!\n",
    "\n",
    "The Review App provides an intuitive UI for domain experts to review and label traces. It's specifically designed for business users who do not have direct access to your Databricks workspace but need to provide quality feedback.\n",
    "\n",
    "**üìö Documentation**\n",
    "\n",
    "- [**Review App**](https://docs.databricks.com/aws/en/mlflow3/genai/human-feedback/concepts/review-app)\n",
    "\n",
    "**‚ñ∂Ô∏è Run the next cell to get a link to the Review App - open the app and label!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T14:22:43.595653Z",
     "iopub.status.busy": "2025-07-29T14:22:43.595362Z",
     "iopub.status.idle": "2025-07-29T14:22:43.602343Z",
     "shell.execute_reply": "2025-07-29T14:22:43.601704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì± Review App URL (for domain experts):\n",
      "   üîó https://db-ml-models-prod-us-west.cloud.databricks.com/ml/review-v2/94e770b23f174005a4b73dcb7cddb011/tasks/labeling/0ab987d3-42b7-4d45-9a93-c301d4e7b3e6\n",
      "   ‚ÑπÔ∏è  Share this link with reviewers to label traces\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('\\nüì± Review App URL (for domain experts):')\n",
    "print(f'   üîó {labeling_session.url}')\n",
    "print('   ‚ÑπÔ∏è  Share this link with reviewers to label traces')\n",
    "\n",
    "print('\\n' + '=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Step 5: Accessing and Using Labeling Results\n",
    "\n",
    "After experts complete labeling, you can see the results in the MLflow UI or access the results through MLflow SDKs to use them to improve your application in several ways:\n",
    "\n",
    "## Using Human Feedback Results\n",
    "\n",
    "- **Understand quality patterns** - Identify common issues and strengths\n",
    "- **Create training data** - Use labeled examples to train custom LLM judges\n",
    "- **Build evaluation datasets** - Convert labeled traces into systematic test sets\n",
    "- **Validate automated metrics** - Check if your automated judges align with human assessment\n",
    "- **Improve prompts** - Use specific feedback to enhance prompt engineering\n",
    "- **Guide model selection** - Compare model performance on human-validated examples\n",
    "\n",
    "**‚ñ∂Ô∏è Run the next cell to see how to programmatically access labeling results!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T14:22:43.611454Z",
     "iopub.status.busy": "2025-07-29T14:22:43.611285Z",
     "iopub.status.idle": "2025-07-29T14:22:43.615139Z",
     "shell.execute_reply": "2025-07-29T14:22:43.614808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ACCESSING LABELING RESULTS\n",
      "============================================================\n",
      "\n",
      "üîç After experts complete labeling, you can access results via the UI:\n",
      "\n",
      "üîó View labeling sessions in MLflow UI:\n",
      "   üè∑Ô∏è Labeling Session: https://db-ml-models-prod-us-west.cloud.databricks.com/ml/experiments/1203903883862022/labeling-sessions?selectedLabelingSessionId=0ab987d3-42b7-4d45-9a93-c301d4e7b3e6\n",
      "\n",
      "üîç After experts complete labeling, you can access results programmatically:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr-a85973d622b4aafae661f7b371cce37d</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-a85973d622b4aafae661...</td>\n",
       "      <td>tr-a85973d622b4aafae661f7b371cce37d</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1754453499937</td>\n",
       "      <td>13571</td>\n",
       "      <td>{'customer_name': 'Energex Solutions', 'user_i...</td>\n",
       "      <td>{'email_subject': 'Energex Solutions: Implemen...</td>\n",
       "      <td>{'mlflow.trace.sizeStats': '{\"total_size_bytes...</td>\n",
       "      <td>{'mlflow.user': 'eric.peter@databricks.com', '...</td>\n",
       "      <td>[{'trace_id': 'qFlz1iK0qvrmYfezcczjfQ==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-1dbcaf6a953f45dcb29108da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr-80b769a1121711c366384ace202dc3f8</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-80b769a1121711c36638...</td>\n",
       "      <td>tr-80b769a1121711c366384ace202dc3f8</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1754453499582</td>\n",
       "      <td>13143</td>\n",
       "      <td>{'customer_name': 'Skyline Realty', 'user_inpu...</td>\n",
       "      <td>{'email_subject': 'Skyline Realty: Follow-up o...</td>\n",
       "      <td>{'mlflow.trace.sizeStats': '{\"total_size_bytes...</td>\n",
       "      <td>{'mlflow.user': 'eric.peter@databricks.com', '...</td>\n",
       "      <td>[{'trace_id': 'gLdpoRIXEcNmOErOIC3D+A==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-fefc0700aece4a0093be6a46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr-1cb816d596868308611d24706e5e7369</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-1cb816d596868308611d...</td>\n",
       "      <td>tr-1cb816d596868308611d24706e5e7369</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1754453496025</td>\n",
       "      <td>11208</td>\n",
       "      <td>{'customer_name': 'BrewMasters Co.', 'user_inp...</td>\n",
       "      <td>{'email_subject': 'BrewMasters Co. - Follow-up...</td>\n",
       "      <td>{'mlflow.trace.sizeStats': '{\"total_size_bytes...</td>\n",
       "      <td>{'mlflow.user': 'eric.peter@databricks.com', '...</td>\n",
       "      <td>[{'trace_id': 'HLgW1ZaGgwhhHSRwbl5zaQ==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-406d6e932fa941c5a400ae22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr-8c23c6e188b8f1d8c835b94553f42e10</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-8c23c6e188b8f1d8c835...</td>\n",
       "      <td>tr-8c23c6e188b8f1d8c835b94553f42e10</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1754453494921</td>\n",
       "      <td>10450</td>\n",
       "      <td>{'customer_name': 'HealthFirst', 'user_input':...</td>\n",
       "      <td>{'email_subject': 'HealthFirst Strategic Plann...</td>\n",
       "      <td>{'mlflow.trace.sizeStats': '{\"total_size_bytes...</td>\n",
       "      <td>{'mlflow.user': 'eric.peter@databricks.com', '...</td>\n",
       "      <td>[{'trace_id': 'jCPG4Yi48djINblFU/QuEA==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-2b0131ba1a1645a9955ac9ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr-f15608821136a5dd85b0792c64149eee</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-f15608821136a5dd85b0...</td>\n",
       "      <td>tr-f15608821136a5dd85b0792c64149eee</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1754453491676</td>\n",
       "      <td>18370</td>\n",
       "      <td>{'customer_name': 'AeroDynamics', 'user_input'...</td>\n",
       "      <td>{'email_subject': 'AeroDynamics Risk Assessmen...</td>\n",
       "      <td>{'mlflow.trace.sizeStats': '{\"total_size_bytes...</td>\n",
       "      <td>{'mlflow.user': 'eric.peter@databricks.com', '...</td>\n",
       "      <td>[{'trace_id': '8VYIghE2pd2FsHksZBSe7g==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-beb09050606e4d229363fe6a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trace_id  \\\n",
       "0  tr-a85973d622b4aafae661f7b371cce37d   \n",
       "1  tr-80b769a1121711c366384ace202dc3f8   \n",
       "2  tr-1cb816d596868308611d24706e5e7369   \n",
       "3  tr-8c23c6e188b8f1d8c835b94553f42e10   \n",
       "4  tr-f15608821136a5dd85b0792c64149eee   \n",
       "\n",
       "                                               trace  \\\n",
       "0  {\"info\": {\"trace_id\": \"tr-a85973d622b4aafae661...   \n",
       "1  {\"info\": {\"trace_id\": \"tr-80b769a1121711c36638...   \n",
       "2  {\"info\": {\"trace_id\": \"tr-1cb816d596868308611d...   \n",
       "3  {\"info\": {\"trace_id\": \"tr-8c23c6e188b8f1d8c835...   \n",
       "4  {\"info\": {\"trace_id\": \"tr-f15608821136a5dd85b0...   \n",
       "\n",
       "                     client_request_id          state   request_time  \\\n",
       "0  tr-a85973d622b4aafae661f7b371cce37d  TraceState.OK  1754453499937   \n",
       "1  tr-80b769a1121711c366384ace202dc3f8  TraceState.OK  1754453499582   \n",
       "2  tr-1cb816d596868308611d24706e5e7369  TraceState.OK  1754453496025   \n",
       "3  tr-8c23c6e188b8f1d8c835b94553f42e10  TraceState.OK  1754453494921   \n",
       "4  tr-f15608821136a5dd85b0792c64149eee  TraceState.OK  1754453491676   \n",
       "\n",
       "   execution_duration                                            request  \\\n",
       "0               13571  {'customer_name': 'Energex Solutions', 'user_i...   \n",
       "1               13143  {'customer_name': 'Skyline Realty', 'user_inpu...   \n",
       "2               11208  {'customer_name': 'BrewMasters Co.', 'user_inp...   \n",
       "3               10450  {'customer_name': 'HealthFirst', 'user_input':...   \n",
       "4               18370  {'customer_name': 'AeroDynamics', 'user_input'...   \n",
       "\n",
       "                                            response  \\\n",
       "0  {'email_subject': 'Energex Solutions: Implemen...   \n",
       "1  {'email_subject': 'Skyline Realty: Follow-up o...   \n",
       "2  {'email_subject': 'BrewMasters Co. - Follow-up...   \n",
       "3  {'email_subject': 'HealthFirst Strategic Plann...   \n",
       "4  {'email_subject': 'AeroDynamics Risk Assessmen...   \n",
       "\n",
       "                                      trace_metadata  \\\n",
       "0  {'mlflow.trace.sizeStats': '{\"total_size_bytes...   \n",
       "1  {'mlflow.trace.sizeStats': '{\"total_size_bytes...   \n",
       "2  {'mlflow.trace.sizeStats': '{\"total_size_bytes...   \n",
       "3  {'mlflow.trace.sizeStats': '{\"total_size_bytes...   \n",
       "4  {'mlflow.trace.sizeStats': '{\"total_size_bytes...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  {'mlflow.user': 'eric.peter@databricks.com', '...   \n",
       "1  {'mlflow.user': 'eric.peter@databricks.com', '...   \n",
       "2  {'mlflow.user': 'eric.peter@databricks.com', '...   \n",
       "3  {'mlflow.user': 'eric.peter@databricks.com', '...   \n",
       "4  {'mlflow.user': 'eric.peter@databricks.com', '...   \n",
       "\n",
       "                                               spans  \\\n",
       "0  [{'trace_id': 'qFlz1iK0qvrmYfezcczjfQ==', 'spa...   \n",
       "1  [{'trace_id': 'gLdpoRIXEcNmOErOIC3D+A==', 'spa...   \n",
       "2  [{'trace_id': 'HLgW1ZaGgwhhHSRwbl5zaQ==', 'spa...   \n",
       "3  [{'trace_id': 'jCPG4Yi48djINblFU/QuEA==', 'spa...   \n",
       "4  [{'trace_id': '8VYIghE2pd2FsHksZBSe7g==', 'spa...   \n",
       "\n",
       "                                         assessments  \n",
       "0  [{'assessment_id': 'a-1dbcaf6a953f45dcb29108da...  \n",
       "1  [{'assessment_id': 'a-fefc0700aece4a0093be6a46...  \n",
       "2  [{'assessment_id': 'a-406d6e932fa941c5a400ae22...  \n",
       "3  [{'assessment_id': 'a-2b0131ba1a1645a9955ac9ca...  \n",
       "4  [{'assessment_id': 'a-beb09050606e4d229363fe6a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Real code examples for accessing labeling results\n",
    "from mlflow_demo.utils.mlflow_helpers import get_mlflow_experiment_id\n",
    "\n",
    "print('üìä ACCESSING LABELING RESULTS')\n",
    "print('=' * 60)\n",
    "\n",
    "print('\\nüîç After experts complete labeling, you can access results via the UI:\\n')\n",
    "\n",
    "generate_labeling_session_link(labeling_session.labeling_session_id)\n",
    "\n",
    "print('\\nüîç After experts complete labeling, you can access results programmatically:\\n')\n",
    "\n",
    "traces = mlflow.search_traces(run_id=labeling_session.mlflow_run_id)\n",
    "\n",
    "traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Summary and Next Steps\n",
    "\n",
    "Congratulations! You've successfully implemented human review workflows for GenAI quality improvement.\n",
    "\n",
    "## What You've Accomplished\n",
    "\n",
    "‚úÖ **Generated traces** for expert review with complex scenarios  \n",
    "‚úÖ **Created labeling schemas** that capture business-critical quality aspects  \n",
    "‚úÖ **Set up labeling sessions** accessible through the Review App  \n",
    "‚úÖ **Learned the workflow** for collecting structured expert feedback\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Human expertise is invaluable** for understanding quality in your domain\n",
    "- **Structured schemas** ensure consistent, actionable feedback\n",
    "- **The Review App** makes it easy for non-technical users to contribute\n",
    "- **Labels become training data** for automated quality assessment\n",
    "\n",
    "**üìö Continue Learning**\n",
    "\n",
    "- [Human Feedback Collection](https://docs.databricks.com/aws/en/mlflow3/genai/human-feedback/) - Complete guide\n",
    "- [Building Evaluation Datasets](https://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/build-eval-dataset) - Use labels for evaluation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_genai_email_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
